# AI Text Detector (Streamlit)
## streamlit:https://aiotdahw5-ce76m3mxb2yjexzhb2tdcb.streamlit.app/
This project provides a lightweight text forensics dashboard that blends fast stylometric heuristics with GPT-2 perplexity (optional) to estimate whether a passage was probably written by a human or generated by an LLM. The user experience is built with Streamlit so that it can run locally or be deployed directly to Streamlit Community Cloud.

## Repository layout

| File / Folder          | Purpose |
|------------------------|---------|
| `app.py`               | Streamlit UI that wires the textbox, option toggles, and result presentation. |
| `detector.py`          | Core detection logic: stylometric feature extraction plus optional GPT-2 perplexity scoring. |
| `requirements.txt`     | Minimal runtime dependencies (Streamlit, numpy, optional NLP stack). |
| `.gitignore`           | Keeps venvs, caches, editor folders, and artefacts out of git. |
| `push_to_github.bat`   | Windows helper script that configures git identity and pushes to a remote. |
| `docs/ARCHITECTURE.md` | Software design notes, heuristics, and extension guidelines. |
| `docs/WORKFLOW.md`     | Day-to-day engineering workflow, testing, calibration, and deployment steps. |

## Quick start (local)

1. **Create & activate a virtual environment**
   ```powershell
   python -m venv .venv
   .\.venv\Scripts\activate
   ```
2. **Install requirements**  
   ```powershell
   pip install -r requirements.txt
   ```  
   `torch` and `transformers` are only needed when enabling GPT-2 perplexity; you can comment them out for low-resource machines.
3. **Launch Streamlit**
   ```powershell
   streamlit run app.py
   ```  
   Streamlit opens `http://localhost:8501` by default. Toggle *Use GPT-2 perplexity* if you want to download and run the Hugging Face model for stronger signals.

## How it works

High-level steps performed when you click **Detect**:

1. `detector.detect_ai` trims the text and extracts stylometric features such as average word length, sentence length, punctuation density, repetition rate, and short-word ratio.
2. If `Use GPT-2 perplexity` is checked **and** `transformers` + `torch` are available, the app loads GPT-2 only once and computes a sliding-window perplexity score (lower values loosely correlate with AI-like text).
3. Each signal is converted into a normalized score and combined via weighted averaging to produce a probability and label (`Likely AI`, `Unclear`, `Likely Human`).
4. The breakdown (raw features, GPT-2 score, and intermediate contributions) is rendered so users can make an informed judgment instead of trusting a black box.

See [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) for deeper implementation details, heuristics, and future work ideas.

## Usage tips

- **Empty or tiny inputs** are flagged as `Unclear`. Encourage at least a few sentences for more stable predictions.
- **Perplexity is optional**: leave it unchecked on machines without the transformer stack or GPU; stylometric heuristics will still run.
- **Prompt templates** are shown in the UI to help analysts capture comparable evidence when interfacing with another LLM.
- **Model caching**: configure `TRANSFORMERS_CACHE` or run once locally to avoid repeated downloads before deploying to Streamlit Cloud.

## Deployment to Streamlit Cloud

1. Push the repository to `https://github.com/g114064015lab/AIOT_DA_HW5.git` (see next section).
2. Login to [share.streamlit.io](https://share.streamlit.io) and create a new app that points to that repository, branch `main`, file `app.py`.
3. In **Advanced settings** you can declare environment variables or secrets (e.g., `TRANSFORMERS_CACHE`, Hugging Face tokens).
4. Streamlit Cloud will install `requirements.txt` and serve the UI globally. Rerun deploys automatically whenever `main` is updated.

## Git workflow

For repeatable pushes from Windows, the included script handles git init / add / commit / push:

```powershell
set GITHUB_TOKEN=<your_PAT>
.\push_to_github.bat https://github.com/g114064015lab/AIOT_DA_HW5.git "Your Name" g114064015@smail.nchu.edu.tw
```

The email defaults to `g114064015@smail.nchu.edu.tw`, which matches the request specification. Replace the PAT with a GitHub token that has `repo` scope or configure SSH manually before running the script.

## Testing & QA checklist

- `py -m compileall app.py detector.py` – verifies there are no syntax errors.
- `py -c "from detector import detect_ai; print(detect_ai('sample text', use_gpt2=False))"` – minimal smoke test without transformers.
- `streamlit run app.py` – interactive verification of the UI and GPT-2 toggle (requires dependencies).
- Manual copy/paste of both human-written and AI-generated paragraphs to validate qualitative behavior.

## Troubleshooting

- **Missing GPU**: the app auto-detects hardware and runs GPT-2 on CPU if CUDA is unavailable. Expect slower estimates on long passages.
- **Out-of-memory when loading GPT-2**: uncheck the Streamlit option so only heuristics run, or switch to a smaller transformer by editing `model_name` in `detector.py`.
- **Slow dependency install**: comment out `torch` / `transformers` inside `requirements.txt` when you only plan to use the heuristic detector.
- **Unreadable README in older clones**: this repository now uses UTF-8 only; pull the latest version if you are still seeing garbled text.

---

Created for HW5 – AIOT Data Analytics. Contributions and extensions are welcome via pull requests.
